{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "CreditCardFraudDetection.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammad0alfares/Credit-Card-Fraud-Detection/blob/master/CreditCardFraudDetection_DT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXpnxtWRFwQW",
        "colab_type": "text"
      },
      "source": [
        "# About The data set\n",
        "\n",
        "The datasets contains transactions made by credit cards in September 2013 by european cardholders. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
        "\n",
        "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, ... V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. **Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.**\n",
        "\n",
        "Given the class imbalance ratio, we recommend measuring the accuracy using the Area Under the Precision-Recall Curve (AUPRC). Confusion matrix accuracy is not meaningful for unbalanced classification.\n",
        "\n",
        "The dataset has been collected and analysed during a research collaboration of Worldline and the Machine Learning Group (http://mlg.ulb.ac.be) of ULB (Université Libre de Bruxelles) on big data mining and fraud detection. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6BVNOhHFwQQ",
        "colab_type": "text"
      },
      "source": [
        "# Import Data from Drive\n",
        "\n",
        "Please download the data from https://www.kaggle.com/mlg-ulb/creditcardfraud\n",
        "\n",
        "Info about data: it is a CSV file, contains 31 features, the last feature is used to classify the transaction whether it is a fraud or not\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qj4vJhgIIE_l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "0fea1f2c-e7c6-41e6-c138-c516d11a3e96"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zTlRkH1IaG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os \n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3A0ap2lIyC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(\"/content/drive/My Drive/CreditCard\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixAvYIe8IiL0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1c5eb45f-bfcf-44af-f574-409fa4958d74"
      },
      "source": [
        "cwd = os.getcwd()\n",
        "print (cwd)\n",
        "!ls -lah"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/CreditCard\n",
            "total 144M\n",
            "-rw------- 1 root root 144M Feb 29 08:20 creditcard.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TP0XZeDoomw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ac2590b-b0f1-450b-fe28-2c1d421c1924"
      },
      "source": [
        "!wc -l creditcard.csv\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "284808 creditcard.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQFvJf4mKj2-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "19291617-a610-4231-9462-6f811dad1ecb"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "url = \"/content/drive/My Drive/CreditCard/creditcard.csv\"\n",
        "\n",
        "creditcard = pd.read_csv(url)\n",
        "\n",
        "creditcard.head()\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0   0.0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
              "1   0.0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
              "2   1.0 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
              "3   1.0 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
              "4   2.0 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgHic8Gm0ufm",
        "colab_type": "text"
      },
      "source": [
        "# Developing a PCA with our partner\n",
        "\n",
        "Whenevr we select our partner , and see the dimentions of data they have , we could use this approach to develop a good PCA for \n",
        "\n",
        "1.   Dimensionality Reduction\n",
        "2.   Featuers Encoding\n",
        "\n",
        "\n",
        "\n",
        "The pipeline will be evaluated using repeated stratified cross-validation with three repeats and 10 folds per repeat. Performance is presented as the mean classification accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0wD_pPBK9qu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "909a48eb-06be-41d6-decf-a98f410000e8"
      },
      "source": [
        "## import from github\n",
        "!rm -rf ./MachineLearning\n",
        "!git clone https://github.com/mkjubran/MachineLearning.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'MachineLearning'...\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 257 (delta 1), reused 6 (delta 1), pack-reused 250\n",
            "Receiving objects: 100% (257/257), 72.83 MiB | 25.38 MiB/s, done.\n",
            "Resolving deltas: 100% (116/116), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPx4OVOVLBVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ignore all future warnings\n",
        "from warnings import simplefilter\n",
        "simplefilter(action='ignore', category=FutureWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQgcjyF0LRvx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5a145fc3-31cd-45b0-c360-97e50913fdf7"
      },
      "source": [
        "# import data \n",
        "import pandas as pd\n",
        "HR = pd.read_csv('./MachineLearning/2_logistic/HR_comma_sep.csv')\n",
        "HR.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>satisfaction_level</th>\n",
              "      <th>last_evaluation</th>\n",
              "      <th>number_project</th>\n",
              "      <th>average_montly_hours</th>\n",
              "      <th>time_spend_company</th>\n",
              "      <th>Work_accident</th>\n",
              "      <th>left</th>\n",
              "      <th>promotion_last_5years</th>\n",
              "      <th>Department</th>\n",
              "      <th>salary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.38</td>\n",
              "      <td>0.53</td>\n",
              "      <td>2</td>\n",
              "      <td>157</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>sales</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>5</td>\n",
              "      <td>262</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>sales</td>\n",
              "      <td>medium</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.11</td>\n",
              "      <td>0.88</td>\n",
              "      <td>7</td>\n",
              "      <td>272</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>sales</td>\n",
              "      <td>medium</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.72</td>\n",
              "      <td>0.87</td>\n",
              "      <td>5</td>\n",
              "      <td>223</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>sales</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.37</td>\n",
              "      <td>0.52</td>\n",
              "      <td>2</td>\n",
              "      <td>159</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>sales</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   satisfaction_level  last_evaluation  ...  Department  salary\n",
              "0                0.38             0.53  ...       sales     low\n",
              "1                0.80             0.86  ...       sales  medium\n",
              "2                0.11             0.88  ...       sales  medium\n",
              "3                0.72             0.87  ...       sales     low\n",
              "4                0.37             0.52  ...       sales     low\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioyiPPyzLotM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0f7d6691-2794-496d-de1d-9fd4104920dc"
      },
      "source": [
        "# apply one hot encoding for the categorical features (salary) \n",
        "dm = pd.get_dummies(HR.salary)\n",
        "HR_GF_merged = pd.concat([HR,dm],axis=1)\n",
        "HR_GF_merged = HR_GF_merged.drop(['salary','medium'],axis=1)\n",
        "HR_GF_merged = HR_GF_merged.drop(['Department'],axis=1)\n",
        "HR_GF_merged.head()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>satisfaction_level</th>\n",
              "      <th>last_evaluation</th>\n",
              "      <th>number_project</th>\n",
              "      <th>average_montly_hours</th>\n",
              "      <th>time_spend_company</th>\n",
              "      <th>Work_accident</th>\n",
              "      <th>left</th>\n",
              "      <th>promotion_last_5years</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.38</td>\n",
              "      <td>0.53</td>\n",
              "      <td>2</td>\n",
              "      <td>157</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>5</td>\n",
              "      <td>262</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.11</td>\n",
              "      <td>0.88</td>\n",
              "      <td>7</td>\n",
              "      <td>272</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.72</td>\n",
              "      <td>0.87</td>\n",
              "      <td>5</td>\n",
              "      <td>223</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.37</td>\n",
              "      <td>0.52</td>\n",
              "      <td>2</td>\n",
              "      <td>159</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   satisfaction_level  last_evaluation  ...  high  low\n",
              "0                0.38             0.53  ...     0    1\n",
              "1                0.80             0.86  ...     0    0\n",
              "2                0.11             0.88  ...     0    0\n",
              "3                0.72             0.87  ...     0    1\n",
              "4                0.37             0.52  ...     0    1\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtiJ9CuALcld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = HR_GF_merged.drop('left',axis=1)\n",
        "y = HR_GF_merged.left"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mu8qGcNNMTOF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1c987000-39f5-45bc-f3bf-3486f07c4ab0"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14999, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHxLfk-F00Wl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "outputId": "c8bfd81f-77ca-4627-b54d-14348127d938"
      },
      "source": [
        "# compare pca number of components with logistic regression algorithm for classification\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from matplotlib import pyplot\n",
        "from sklearn.preprocessing import StandardScaler\n",
        " \n",
        "# get the dataset\n",
        "def get_dataset():\n",
        "    X = HR_GF_merged.drop('left',axis=1)\n",
        "    y = HR_GF_merged.left\n",
        "    ## X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
        "    ## Data here depend on our partner system and feilds they have\n",
        "    return X,y\n",
        " \n",
        "# get a list of models to evaluate\n",
        "def get_models(dx):\n",
        "\tn_featuers = dx.shape[1] + 1\n",
        "\tmodels = dict()\n",
        "\tfor i in range(1,n_featuers):\n",
        "\t\tsteps = [('scale', StandardScaler()), ('pca', PCA(n_components=i)), ('m', LogisticRegression())]\n",
        "\t\tmodels[str(i)] = Pipeline(steps=steps)\n",
        "\treturn models\n",
        " \n",
        "# evaluate a given model using cross-validation\n",
        "def evaluate_model(model):\n",
        "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
        "\treturn scores\n",
        " \n",
        "# define dataset\n",
        "X, y = get_dataset()\n",
        "# get the models to evaluate\n",
        "models = get_models(X)\n",
        "# evaluate the models and store results\n",
        "results, names = list(), list()\n",
        "for name, model in models.items():\n",
        "\tscores = evaluate_model(model)\n",
        "\tresults.append(scores)\n",
        "\tnames.append(name)\n",
        "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
        "# plot model performance for comparison\n",
        "pyplot.boxplot(results, labels=names, showmeans=True)\n",
        "pyplot.xticks(rotation=45)\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">1 0.762 (0.000)\n",
            ">2 0.768 (0.005)\n",
            ">3 0.773 (0.007)\n",
            ">4 0.773 (0.007)\n",
            ">5 0.773 (0.006)\n",
            ">6 0.771 (0.007)\n",
            ">7 0.770 (0.007)\n",
            ">8 0.768 (0.008)\n",
            ">9 0.788 (0.007)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89YHP6t3T4Vt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "d6b6db77-3064-4e8c-d892-01c11951c2cf"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "X = HR_GF_merged.drop('left',axis=1)\n",
        "y = HR_GF_merged.left\n",
        "\n",
        "pca = PCA(n_components=9)\n",
        "principalComponents = pca.fit_transform(X)\n",
        "## fit then transform ( to keep the model for prediction transfomation )\n",
        "feat_cols = ['V'+str(i+1) for i in range(principalComponents.shape[1])]\n",
        "principalDf = pd.DataFrame(data = principalComponents, columns= feat_cols)\n",
        "principalDf\n",
        "\n",
        "finalDf = pd.concat([principalDf, y], axis = 1)\n",
        "finalDf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>left</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-44.068284</td>\n",
              "      <td>-0.693580</td>\n",
              "      <td>1.198803</td>\n",
              "      <td>-0.528518</td>\n",
              "      <td>-0.162921</td>\n",
              "      <td>0.001922</td>\n",
              "      <td>0.267210</td>\n",
              "      <td>0.040933</td>\n",
              "      <td>-0.006774</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>60.967814</td>\n",
              "      <td>2.345007</td>\n",
              "      <td>0.079979</td>\n",
              "      <td>0.425182</td>\n",
              "      <td>-0.131498</td>\n",
              "      <td>-0.168474</td>\n",
              "      <td>-0.258448</td>\n",
              "      <td>0.000223</td>\n",
              "      <td>-0.042169</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>70.980424</td>\n",
              "      <td>0.917171</td>\n",
              "      <td>-2.317960</td>\n",
              "      <td>0.447848</td>\n",
              "      <td>-0.179813</td>\n",
              "      <td>-0.214749</td>\n",
              "      <td>0.392906</td>\n",
              "      <td>-0.067905</td>\n",
              "      <td>-0.004526</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>21.966453</td>\n",
              "      <td>1.620742</td>\n",
              "      <td>-0.551044</td>\n",
              "      <td>-0.536236</td>\n",
              "      <td>-0.122887</td>\n",
              "      <td>0.044629</td>\n",
              "      <td>-0.195844</td>\n",
              "      <td>-0.053117</td>\n",
              "      <td>-0.010388</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-42.068416</td>\n",
              "      <td>-0.706361</td>\n",
              "      <td>1.216685</td>\n",
              "      <td>-0.528794</td>\n",
              "      <td>-0.163649</td>\n",
              "      <td>0.000984</td>\n",
              "      <td>0.279561</td>\n",
              "      <td>0.050448</td>\n",
              "      <td>-0.007671</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14994</th>\n",
              "      <td>-50.067874</td>\n",
              "      <td>-0.654870</td>\n",
              "      <td>1.144580</td>\n",
              "      <td>-0.528056</td>\n",
              "      <td>-0.161497</td>\n",
              "      <td>0.003747</td>\n",
              "      <td>0.238148</td>\n",
              "      <td>0.000914</td>\n",
              "      <td>-0.002548</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14995</th>\n",
              "      <td>-41.068523</td>\n",
              "      <td>-0.713397</td>\n",
              "      <td>1.226846</td>\n",
              "      <td>-0.528665</td>\n",
              "      <td>-0.163721</td>\n",
              "      <td>0.001076</td>\n",
              "      <td>0.287034</td>\n",
              "      <td>0.090252</td>\n",
              "      <td>-0.012329</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14996</th>\n",
              "      <td>-58.067432</td>\n",
              "      <td>-0.603473</td>\n",
              "      <td>1.073673</td>\n",
              "      <td>-0.529098</td>\n",
              "      <td>-0.164342</td>\n",
              "      <td>0.000914</td>\n",
              "      <td>0.271145</td>\n",
              "      <td>0.029087</td>\n",
              "      <td>-0.005428</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14997</th>\n",
              "      <td>78.969719</td>\n",
              "      <td>0.579865</td>\n",
              "      <td>-1.295757</td>\n",
              "      <td>-0.533209</td>\n",
              "      <td>-0.165371</td>\n",
              "      <td>-0.004118</td>\n",
              "      <td>0.395844</td>\n",
              "      <td>-0.172810</td>\n",
              "      <td>0.024315</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14998</th>\n",
              "      <td>-43.068355</td>\n",
              "      <td>-0.699940</td>\n",
              "      <td>1.207767</td>\n",
              "      <td>-0.528812</td>\n",
              "      <td>-0.163694</td>\n",
              "      <td>0.000981</td>\n",
              "      <td>0.279145</td>\n",
              "      <td>0.049724</td>\n",
              "      <td>-0.007602</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14999 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              V1        V2        V3  ...        V8        V9  left\n",
              "0     -44.068284 -0.693580  1.198803  ...  0.040933 -0.006774     1\n",
              "1      60.967814  2.345007  0.079979  ...  0.000223 -0.042169     1\n",
              "2      70.980424  0.917171 -2.317960  ... -0.067905 -0.004526     1\n",
              "3      21.966453  1.620742 -0.551044  ... -0.053117 -0.010388     1\n",
              "4     -42.068416 -0.706361  1.216685  ...  0.050448 -0.007671     1\n",
              "...          ...       ...       ...  ...       ...       ...   ...\n",
              "14994 -50.067874 -0.654870  1.144580  ...  0.000914 -0.002548     1\n",
              "14995 -41.068523 -0.713397  1.226846  ...  0.090252 -0.012329     1\n",
              "14996 -58.067432 -0.603473  1.073673  ...  0.029087 -0.005428     1\n",
              "14997  78.969719  0.579865 -1.295757  ... -0.172810  0.024315     1\n",
              "14998 -43.068355 -0.699940  1.207767  ...  0.049724 -0.007602     1\n",
              "\n",
              "[14999 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcx5vmpFA2Yx",
        "colab_type": "text"
      },
      "source": [
        "Later , our partner would use the same input feilds (featuers ) and the number of componenets to generate a PCA data, then call our API "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbBfZm9sforQ",
        "colab_type": "text"
      },
      "source": [
        "# How to Deal with Imbalanced Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XS8Kp_VNFwQX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "27b50980-d788-4f77-ce13-e33b7bd7140d"
      },
      "source": [
        "print(creditcard.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(284807, 31)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsSJVyyYFwQa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "de73bab7-8479-4d2c-da3b-5087f5216a04"
      },
      "source": [
        "print(creditcard.columns)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
            "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
            "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
            "       'Class'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UteXbVeOqDjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## check null values \n",
        "print (f'Number if the records = {creditcard.shape[0]}')\n",
        "pd.isnull(creditcard).sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQ3w5P7UFwQc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "45deccc4-49d5-4aa7-da88-f9749919070c"
      },
      "source": [
        "creditcard[\"Class\"].value_counts()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    284315\n",
              "1       492\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vQ7quX2W8Rt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a590d44-9bc0-4092-a182-f10525a82a35"
      },
      "source": [
        "## the data is highly unbalanced\n",
        "positive =  creditcard[creditcard.Class == 1]\n",
        "positive_cnt = positive.shape[0]\n",
        "\n",
        "negative =  creditcard[creditcard.Class == 0]\n",
        "negative_cnt = negative.shape[0]\n",
        "\n",
        "fruad_pct= positive_cnt / (positive_cnt  + negative_cnt )\n",
        "print(f'records count = {creditcard.shape[0]} , fruad records = {positive_cnt} ,  the positive class (frauds) {round(fruad_pct*100,3)}%')\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "records count = 284807 , fruad records = 492 ,  the positive class (frauds) 0.173%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-UqsmKseXC0",
        "colab_type": "text"
      },
      "source": [
        "Observations:\n",
        "\n",
        "We will use the Credit Card Fraud Detection Dataset available on Kaggle. The dataset is high imbalanced, with only 0.17% of transactions being classified as fraudulent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEmzNbMFpPau",
        "colab_type": "text"
      },
      "source": [
        "**Imbalanced Classes**\n",
        "\n",
        "Most machine learning algorithms work best when the number of samples in each class are about equal. This is because most algorithms are designed to maximize accuracy and reduce error.\n",
        "\n",
        "\n",
        "https://towardsdatascience.com/methods-for-dealing-with-imbalanced-data-5b761be45a18\n",
        "\n",
        "\n",
        "We explored 5 different methods for dealing with imbalanced datasets:\n",
        "Change the performance metric\n",
        "\n",
        "\n",
        "1.   Change the performance metric\n",
        "2.   Change the algorithm\n",
        "3.   Oversample minority class\n",
        "4.   Undersample majority class\n",
        "5.   Generate synthetic samples\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1-eO1jrs3Iu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bcad33de-51aa-4e3e-b9f6-4c020682a571"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x = creditcard.drop( ['Class','Time'],axis=1)\n",
        "y = creditcard.Class\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2)\n",
        "print('size of test dataset = {}, size of traing data = {}, percentage = {}%'.format(len(x_test),len(x_train),len(x_test)*100/(len(x_test) + len(x_train))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "size of test dataset = 56962, size of traing data = 227845, percentage = 20.000210668979342%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWLnDq36sX3V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2c7e9a28-c28c-4336-9a58-0f60c4a98152"
      },
      "source": [
        "# Modeling the data as is\n",
        "# Train model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model_lr = LogisticRegression(solver='liblinear').fit(x_train, y_train)\n",
        " \n",
        "# Checking accuracy\n",
        "acc_model_lr = model_lr.score(x_train, y_train)\n",
        "acc_test_lr = model_lr.score(x_test, y_test)\n",
        "\n",
        "print(acc_model_lr*100)\n",
        "print(acc_test_lr*100)\n",
        "\n",
        "# Predict on training set\n",
        "lr_pred = model_lr.predict(x_test)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99.9174877658057\n",
            "99.92275552122467\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e3XmIUXwiTV",
        "colab_type": "text"
      },
      "source": [
        "high score !\n",
        "but Let’s see what happens when we apply these F1 and recall scores to our logistic regression from above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1TA1eHS9FFt",
        "colab_type": "text"
      },
      "source": [
        "**1-Change the performance metric**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TR5HokN_JkQT",
        "colab_type": "text"
      },
      "source": [
        "**To be reminded**\n",
        "\n",
        " Classifying a single point can result in \n",
        " \n",
        "\n",
        "1.   a true positive (truth = 1, guess = 1)\n",
        "2.   a true negative (truth = 0, guess = 0)\n",
        "1.   a false positive (truth = 0, guess = 1) \n",
        "2.   a false negative (truth = 1, guess = 0)\n",
        "\n",
        "TP            FP\n",
        "\n",
        "FN            TN\n",
        "\n",
        "\n",
        "1) Accuracy measures how many classifications your algorithm got correct out of every classification it made.\n",
        "**CA =(TP+TN)/ (TP+TN+ FP+FN)**\n",
        "\n",
        "2) Precision measures : actually positive TP divided by total number of points predicted by model as positive\n",
        ". **P = TP/(TP+FP)**\n",
        "\n",
        "3) Recall measures : actually are positive TP divided by total number of positive points\n",
        "**R =TP/(TP+FN)**\n",
        "\n",
        "4) Precision and recall are tied to each other. As one goes up, the other will go down.\n",
        "\n",
        "5) F1 score is a combination of precision and recall, **F1** score will be low if either precision or recall is low."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GxORYKIe9BA",
        "colab_type": "text"
      },
      "source": [
        "**which error we have to reduce depends on problem, requirements**\n",
        "\n",
        "**Minimizing False Positive:** high Precision\n",
        "\n",
        "Minimizing genuine trans but model detects fraud/Positive\n",
        "\n",
        "if we don't want to interupt transaction by mistake \n",
        "\n",
        "**Minimizing False Negative:** high recall\n",
        "\n",
        "Minimizing fraud trans but model detects genuine/Negative\n",
        "\n",
        "if we don't want credit-card holder to loss money\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwUjJMaxu0dj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1-Change the performance metric\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCybQiSzIYGM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "8a503571-d9a3-43df-cb67-59bbb16ada04"
      },
      "source": [
        "acc_test_lr= accuracy_score(y_test, lr_pred)*100\n",
        "acc_pr_lr= precision_score(y_test, lr_pred, average='micro')*100\n",
        "acc_recall_lr= recall_score(y_test, lr_pred)*100\n",
        "acc_f1_lr= f1_score(y_test, lr_pred)*100\n",
        "\n",
        "print('accuracy_score= ', acc_test_lr)\n",
        "print('pr_score= ', acc_pr_lr)\n",
        "print('recall_score= ', acc_recall_lr)\n",
        "print('f1_score= ',acc_f1_lr)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy_score=  99.92275552122467\n",
            "pr_score=  99.92275552122467\n",
            "recall_score=  63.0\n",
            "f1_score=  74.11764705882354\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMRToKt2wsZE",
        "colab_type": "text"
      },
      "source": [
        "These scores don’t look quite so impressive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYmVAyWK9M8c",
        "colab_type": "text"
      },
      "source": [
        "**2. Change the algorithm**\n",
        "\n",
        "Decision trees frequently perform well on imbalanced data. They work by learning a hierarchy of if/else questions and this can force both classes to be addressed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApEW48HYwJqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2. Change the algorithm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# train model\n",
        "model_rfc = RandomForestClassifier(n_estimators=10).fit(x_train, y_train)\n",
        "\n",
        "# predict on test set\n",
        "rfc_pred = model_rfc.predict(x_test)\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GK9cFgI9yY3k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "bd063bab-c704-4767-a66e-50daefd42dde"
      },
      "source": [
        "acc_test_rfc= accuracy_score(y_test, rfc_pred)*100\n",
        "acc_pr_rfc= precision_score(y_test, rfc_pred, average='micro')*100\n",
        "acc_recall_rfc= recall_score(y_test, rfc_pred)*100\n",
        "acc_f1_rfc= f1_score(y_test, rfc_pred)*100\n",
        "\n",
        "\n",
        "print('accuracy_score= ', acc_test_rfc)\n",
        "print('pr_score= ', acc_pr_rfc)\n",
        "print('recall_score= ', acc_recall_rfc)\n",
        "print('f1_score= ', acc_f1_rfc)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy_score=  99.95259997893332\n",
            "pr_score=  99.95259997893332\n",
            "recall_score=  78.0\n",
            "f1_score=  85.24590163934427\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3J6Oj9ZwP_7",
        "colab_type": "text"
      },
      "source": [
        "While our accuracy score is slightly lower, both F1 and recall have increased as compared to logistic regression! It appears that for this specific problem, random forest may be a better choice of model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtUcKfecjbyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del x,y,x_train, x_test, y_train, y_test"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1J-3EtLM9TsA",
        "colab_type": "text"
      },
      "source": [
        "**3. Resampling Techniques — Oversample minority class**\n",
        "\n",
        "we would split into test and train sets BEFORE trying oversampling techniques."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcryIcmZ-GpU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "85e1d791-b817-4788-ba53-269090bd2772"
      },
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "# Separate input features and target\n",
        "y = creditcard.Class\n",
        "X = creditcard.drop(['Class','Time'], axis=1)\n",
        "\n",
        "# setting up testing and training sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)\n",
        "\n",
        "# concatenate our training data back together\n",
        "X = pd.concat([X_train, y_train], axis=1)\n",
        "\n",
        "# separate minority and majority classes\n",
        "not_fraud = X[X.Class==0]\n",
        "fraud = X[X.Class==1]\n",
        "\n",
        "# upsample minority\n",
        "fraud_upsampled = resample(fraud,\n",
        "                          replace=True, # sample with replacement\n",
        "                          n_samples=len(not_fraud), # match number in majority class\n",
        "                          random_state=27) # reproducible results\n",
        "\n",
        "# combine majority and upsampled minority\n",
        "upsampled = pd.concat([not_fraud, fraud_upsampled])\n",
        "\n",
        "# check new class counts\n",
        "upsampled.Class.value_counts()\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    213245\n",
              "0    213245\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAf4TYcP-Kua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# trying logistic regression again with the balanced dataset\n",
        "y_train = upsampled.Class\n",
        "X_train = upsampled.drop('Class', axis=1)\n",
        "\n",
        "##upsampled = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
        "upsampled = RandomForestClassifier(n_estimators=10).fit(X_train, y_train)\n",
        "\n",
        "upsampled_pred = upsampled.predict(X_test)\n",
        "   "
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7PERFMF_I_K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "fd4861de-4ae4-43dc-ba98-bb36ea139261"
      },
      "source": [
        "acc_test_ups= accuracy_score(y_test, upsampled_pred)*100\n",
        "acc_pr_ups = precision_score(y_test, upsampled_pred, average='micro')*100\n",
        "acc_recall_ups= recall_score(y_test, upsampled_pred)*100\n",
        "acc_f1_ups= f1_score(y_test, upsampled_pred)*100\n",
        "\n",
        "print('accuracy_score= ', acc_test_ups)\n",
        "print('pr_score= ', acc_pr_ups)\n",
        "print('recall_score= ', acc_recall_ups)\n",
        "print('f1_score= ', acc_f1_ups)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy_score=  99.95786635206876\n",
            "pr_score=  99.95786635206876\n",
            "recall_score=  79.54545454545455\n",
            "f1_score=  87.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDcZlMI2hQLt",
        "colab_type": "text"
      },
      "source": [
        "Our recall score increased, but F1 is much lower than with either our baseline logistic regression or random forest from above. Let’s see if undersampling might perform better here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSnI-caylaWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del X,y,X_train, X_test, y_train, y_test"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3bb_dal9VpK",
        "colab_type": "text"
      },
      "source": [
        "**4. Resampling techniques — Undersample majority class**\n",
        "\n",
        "Again, we would split into test and train sets BEFORE trying Undersample techniques."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUtI9f2d_bQl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "879e27b7-02cd-473d-9f4f-567b6818fa38"
      },
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "# Separate input features and target\n",
        "y = creditcard.Class\n",
        "X = creditcard.drop(['Class','Time'], axis=1)\n",
        "\n",
        "# setting up testing and training sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)\n",
        "\n",
        "# concatenate our training data back together\n",
        "X = pd.concat([X_train, y_train], axis=1)\n",
        "\n",
        "# separate minority and majority classes\n",
        "not_fraud = X[X.Class==0]\n",
        "fraud = X[X.Class==1]\n",
        "\n",
        "# downsample majority\n",
        "not_fraud_downsampled = resample(not_fraud,\n",
        "                                replace = False, # sample without replacement\n",
        "                                n_samples = len(fraud), # match minority n\n",
        "                                random_state = 27) # reproducible results\n",
        "\n",
        "# combine minority and downsampled majority\n",
        "downsampled = pd.concat([not_fraud_downsampled, fraud])\n",
        "\n",
        "# checking counts\n",
        "downsampled.Class.value_counts()\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    360\n",
              "0    360\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u60PDkvu_jVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# trying logistic regression again with the undersampled dataset\n",
        "\n",
        "y_train = downsampled.Class\n",
        "X_train = downsampled.drop('Class', axis=1)\n",
        "\n",
        "##undersampled = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
        "undersampled = RandomForestClassifier(n_estimators=10).fit(X_train, y_train)\n",
        "\n",
        "undersampled_pred = undersampled.predict(X_test)\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2gCZU4HRB8d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "86aa27ca-f59a-44c5-d673-82240f932db5"
      },
      "source": [
        "acc_test_undr= accuracy_score(y_test, undersampled_pred)*100\n",
        "acc_pr_undr = precision_score(y_test, undersampled_pred, average='micro')*100\n",
        "acc_recall_undr= recall_score(y_test, undersampled_pred)*100\n",
        "acc_f1_undr= f1_score(y_test, undersampled_pred)*100\n",
        "\n",
        "\n",
        "print('accuracy_score= ', acc_test_undr)\n",
        "print('pr_score= ',acc_pr_undr )\n",
        "print('recall_score= ', acc_recall_undr)\n",
        "print('f1_score= ', acc_f1_undr)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy_score=  97.39333164798741\n",
            "pr_score=  97.39333164798741\n",
            "recall_score=  86.36363636363636\n",
            "f1_score=  10.9404990403071\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3rIRd-sS3tT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del X,y,X_train, X_test, y_train, y_test"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nOE32ubhk3T",
        "colab_type": "text"
      },
      "source": [
        "Undersampling underperformed oversampling in this case. Let’s try one more method for handling imbalanced data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dvc8wHL9deR",
        "colab_type": "text"
      },
      "source": [
        "**5. Generate synthetic samples SMOTE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8uADKcDh1K4",
        "colab_type": "text"
      },
      "source": [
        "Again, it’s important to generate the new samples only in the training set to ensure our model generalizes well to unseen data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldo42zMI__x-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "8e8c6209-5ba6-4484-d24f-7cec5b01d1bf"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Separate input features and target\n",
        "y = creditcard.Class\n",
        "X = creditcard.drop('Class', axis=1)\n",
        "\n",
        "# setting up testing and training sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)\n",
        "\n",
        "sm = SMOTE(random_state=27, ratio=1.0)\n",
        "X_train, y_train = sm.fit_sample(X_train, y_train)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THYFI4moACvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##smote = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
        "smote = RandomForestClassifier(n_estimators=10).fit(X_train, y_train)\n",
        "smote_pred = smote.predict(X_test)\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-C9A2oLbR9-h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "35cd0a26-6163-4d13-f046-3ee584b10694"
      },
      "source": [
        "acc_test_smote= accuracy_score(y_test, smote_pred)*100\n",
        "acc_pr_smote = precision_score(y_test, smote_pred, average='micro')*100\n",
        "acc_recall_smote= recall_score(y_test, smote_pred)*100\n",
        "acc_f1_smote= f1_score(y_test, smote_pred)*100\n",
        "\n",
        "\n",
        "print('accuracy_score= ', acc_test_smote)\n",
        "print('pr_score= ', acc_pr_smote)\n",
        "print('recall_score= ', acc_recall_smote)\n",
        "print('f1_score= ', acc_f1_smote)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy_score=  99.94663071262043\n",
            "pr_score=  99.94663071262043\n",
            "recall_score=  81.81818181818183\n",
            "f1_score=  85.03937007874016\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZTs-EleYzcW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "14d2339c-c268-410a-80e1-025d27089972"
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "t2 = PrettyTable(['Accuracy'  ,'Logistic'     ,'RF'              ,'Oversample'         ,'Undersample'   ,'SMOTE' ])\n",
        "t2.add_row(['accuracy_score'  ,acc_test_lr    , acc_test_rfc     ,acc_test_ups         ,acc_test_undr   ,acc_test_smote])\n",
        "t2.add_row(['pr_score'        ,acc_pr_lr      , acc_pr_rfc       ,acc_pr_ups           ,acc_pr_undr     ,acc_pr_smote])\n",
        "t2.add_row(['recall_score'    ,acc_recall_lr  , acc_recall_rfc   ,acc_recall_ups       ,acc_recall_undr ,acc_recall_smote])\n",
        "t2.add_row(['f1_score'        ,acc_f1_lr      , acc_f1_rfc       ,acc_f1_ups           ,acc_f1_undr     ,acc_f1_smote])\n",
        "print(t2)\n",
        "\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------+-------------------+-------------------+-------------------+-------------------+-------------------+\n",
            "|    Accuracy    |      Logistic     |         RF        |     Oversample    |    Undersample    |       SMOTE       |\n",
            "+----------------+-------------------+-------------------+-------------------+-------------------+-------------------+\n",
            "| accuracy_score | 99.92275552122467 | 99.95259997893332 | 99.95786635206876 | 97.39333164798741 | 99.94663071262043 |\n",
            "|    pr_score    | 99.92275552122467 | 99.95259997893332 | 99.95786635206876 | 97.39333164798741 | 99.94663071262043 |\n",
            "|  recall_score  |        63.0       |        78.0       | 79.54545454545455 | 86.36363636363636 | 81.81818181818183 |\n",
            "|    f1_score    | 74.11764705882354 | 85.24590163934427 |        87.5       |  10.9404990403071 | 85.03937007874016 |\n",
            "+----------------+-------------------+-------------------+-------------------+-------------------+-------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ64Ee9f9yTh",
        "colab_type": "text"
      },
      "source": [
        "It appears for this particular dataset random forest with SMOTE are the best of the options we tried here.\n",
        "\n",
        "in our case we are looking to minimize false negative (minimize loses), so we are looking for high recall score , Undersample in this case results in a very samall quantity of data to train the model on, while SMOTE increased the recall score, so we would consider SMOTE+RF approach.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCd7VV7CtD7B",
        "colab_type": "text"
      },
      "source": [
        "# Execlde some Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCu2Infx83Pt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "cf45805a-70da-468d-9934-f8fd1629fa70"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "col='V28'\n",
        "## V13 V20 V23 V28 seems irrelevant \n",
        "\n",
        "sns.distplot(creditcard[col][creditcard.Class == 1], bins=50, color='r')\n",
        "sns.distplot(creditcard[col][creditcard.Class == 0], bins=50, color='g')\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEGCAYAAAB1iW6ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3hV9Z3v8fd37wSCAgFMwh2CgEWsopaiaKdDpze1PeLptNWOta0e9WnVHj3W6W2eo9WZ48ypz9iLVTtUPV5qRWu1aoVabLVUW5CAiFwEUZAEAoRrEhKSffmeP/baOztpYlZsYC82n9fz8JC19srOb2n66cffWuu3zd0REZEjX6zQAxARkf6hQBcRKRIKdBGRIqFAFxEpEgp0EZEiUVKoH1xRUeHV1dWF+vEiIkek5cuX73L3yu5eK1igV1dXU1NTU6gfLyJyRDKzd3p6TVMuIiJFQoEuIlIkFOgiIkVCgS4iUiQU6CIiRUKBLiJSJBToIiJFQoEuIlIkFOjSJ0+se4Lpd04nlU4Veigi0oUCXfpkXcM61u1aR1uqrdBDEZEuFOjSJynPNHM1dJHoUaBLn2SDPBvsIhIdvQa6mY03sxfMbK2ZrTGza7s5Zo6Z7TezlcGfGw/NcKXQ1NBFoivMaotJ4BvuvsLMhgDLzWyRu6/tctyf3P3T/T9EiZJkOgmooYtEUa8N3d3r3X1F8HUTsA4Ye6gHJtGUm3JRQxeJnD7NoZtZNXAasLSbl2eb2WtmttDMTurh+680sxozq2loaOjzYKXwclMuaugikRM60M1sMPAr4Dp3b+zy8gpgorvPAO4Aft3de7j7PHef6e4zKyu7/cANiTg1dJHoChXoZlZKJswfdvcnur7u7o3u3hx8vQAoNbOKfh2pRIIaukh0hbnLxYB7gXXufnsPx4wKjsPMZgXvu7s/ByrRoIYuEl1h7nI5G7gEeN3MVgb7vgtMAHD3nwKfBb5mZkmgFbjI3f0QjFcKTA1dJLp6DXR3fwmwXo75CfCT/hqURJcaukh06UlR6RM1dJHoUqBLn+hJUZHoUqBLn2gtF5HoUqBLn6ihi0SXAl36RA1dJLoU6NInaugi0aVAlz5RQxeJLgW69Ikaukh0KdClT9TQRaJLgS59ooYuEl0KdOkTNXSR6FKgS5+ooYtElwJd+iQb5GlPF3gkItKVAl36RItziUSXAl36RMvnikSXAl36RA1dJLoU6NInaugi0aVAlz5RQxeJLgW69Ikaukh0KdClT9TQRaJLgS59ooYuEl0KdOkTNXSR6FKgS5+ooYtElwJd+kQNXSS6FOjSJ2roItGlQJc+UUMXiS4FuvRJMp0E1NBFokiBLn2iD7gQiS4FuvSJPuBCJLoU6NInaugi0aVAlz5RQxeJrl4D3czGm9kLZrbWzNaY2bXdHGNm9mMz22hmq8zs9EMzXCk0NXSR6CoJcUwS+Ia7rzCzIcByM1vk7mvzjjkXmBr8OQO4O/hbioi74zighi4SRb02dHevd/cVwddNwDpgbJfD5gIPesYSYJiZje730UpB5bdyNXSR6OnTHLqZVQOnAUu7vDQWqM3bruOvQ1+OcPmtXA1dJHpCB7qZDQZ+BVzn7o3v5YeZ2ZVmVmNmNQ0NDe/lLaSA1NBFoi1UoJtZKZkwf9jdn+jmkK3A+LztccG+Ttx9nrvPdPeZlZWV72W8UkBq6CLRFuYuFwPuBda5++09HPY08KXgbpczgf3uXt+P45QIUEMXibYwd7mcDVwCvG5mK4N93wUmALj7T4EFwHnARqAFuLT/hyqF1qmhK9BFIqfXQHf3lwDr5RgHru6vQUk05Yd42tMFHImIdEdPikpomkMXiTYFuoSmOXSRaFOgS2hq6CLRpkCX0NTQRaJNgS6hqaGLRJsCXUJTQxeJNgW6hKaGLhJtCnQJTQ1dJNoU6BKaGrpItCnQJTQ1dJFoU6BLaGroItGmQJfQ1NBFok2BLqFlW3nc4mroIhGkQJfQsq18QHyAGrpIBCnQJbRsKx8QH6CGLhJBCnQJTQ1dJNoU6BKaGrpItCnQJTQ1dJFoU6BLaGroItGmQJfQ1NBFok2BLqEl00lADV0kqhToElqnKRc1dJHIUaBLaJ2mXNTQRSJHgS6hqaGLRJsCXUJTQxeJNgW6hKaGLhJtCnQJTQ1dJNoU6BJafkNPe7rAoxGRrhToEpoeLBKJNgW6hKZH/0WiTYEuoamhi0Rbr4FuZveZ2U4zW93D63PMbL+ZrQz+3Nj/w5Qo6DqH7u4FHpGI5CsJccz9wE+AB9/lmD+5+6f7ZUQSWfkNHSDtaeIWL+SQRCRPrw3d3RcDew7DWCTi8hs6oGkXkYjprzn02Wb2mpktNLOT+uk9JWKyAV4aK81s68KoSKSEmXLpzQpgors3m9l5wK+Bqd0daGZXAlcCTJgwoR9+tBxOqXQKwyiJZX5t1NBFouVvbuju3ujuzcHXC4BSM6vo4dh57j7T3WdWVlb+rT9aDrOUp4jH4sRjmXlzNXSRaPmbA93MRpmZBV/PCt5z99/6vhI9qXSKuMVzF0LV0EWipdcpFzN7BJgDVJhZHXATUArg7j8FPgt8zcySQCtwket+tqKkhi4Sbb0Gurt/oZfXf0LmtkYpcmroItGmJ0UlNDV0kWhToEtoaugi0aZAl9DU0EWiTYEuoamhi0SbAl1CU0MXiTYFuoSWcjV0kShToEtoqbQaukiUKdAlNDV0kWhToEtoaugi0aZAl9DU0EWiTYEuoWUbesxiuW0RiQ4FuoSWa+gxNXSRKFKgS2i5OXTTHLpIFCnQJbRkOqmGLhJhCnQJLeUpSmIlxH/zbGZbDV0kUhToElpuyiX4tUl7usAjEpF8CnQJLXdRNPi10ZSLSLQo0CW0joZuuW0RiQ4FuoTW8WCRGrpIFCnQJbSuc+hq6CLRokCX0DSHLhJtCnQJrePBIjV0kShSoEtoHQ3dctsiEh0KdAlNc+gi0aZAl9A0hy4SbQp0CS3X0F94MbctItGhQJfQUp4i3p4k/tvf5bZFJDoU6BJaKp0i3txC3IPt9rbCDkhEOlGgS2gpTxFvbSUerMmVatxX2AGJSCcKdAktlU4Rb091NPTG/YUdkIh0okCX0FKeIp5IdjT0JgW6SJSUFHoAcuRIpVPEk8mOht7cWNgBiUgnvTZ0M7vPzHaa2eoeXjcz+7GZbTSzVWZ2ev8PU6Igd5dLtqE3NxV2QCLSSZgpl/uBc97l9XOBqcGfK4G7//ZhSRSl0inibQniA8sy2+0HCzwiEcnXa6C7+2Jgz7scMhd40DOWAMPMbHR/DVCiI9PQE8TKBmW2dduiSKT0x0XRsUBt3nZdsO+vmNmVZlZjZjUNDQ398KPlcMo09HYFukhEHda7XNx9nrvPdPeZlZWVh/NHSz/INnQGDiSehlRCgS4SJf1xl8tWYHze9rhgnxSJecvnkfbMldCWA/vZFi8l7pBKtBd4ZCKSrz8a+tPAl4K7Xc4E9rt7fT+8r0SIe+ZexZJEmmRJjJiroYtETa8N3cweAeYAFWZWB9wElAK4+0+BBcB5wEagBbj0UA1WCifb0EtTaVKlceJupJJq6CJR0mugu/sXenndgav7bUQSSdlAL0mkSZfEMw09mSjwqEQknx79l1ByDT2RIlkSJ4YaukjUKNAllFxDT6ZJlcSIu5HWB1yIRIoCXUJxMhdFSxOZOfQYustFJGoU6BJK/pRLKjvlQrrAoxKRfAp0CSUb6AMS6bxAdwhuZxSRwlOgSyjZQI+nIVUaI+ZGyoB2TbuIRIUCXULJBbrT0dBjwEGtuCgSFQp0CaVTQy+JE7OgoSvQRSJDgS6hdGropXFMDV0kchToEkp+Q0+WxDJTLmroIpGiQJdQsotzxZ3Mo/8WNPQ2LdAlEhUKdAmlc0MPplzU0EUiRYEuoXSdQ49ZTHPoIhGjQJdQOt/lElNDF4kgBbqEkqbLfehq6CKRo0CXUHIXRdPBbYvZ+9B1UVQkMhToEkrXJ0VRQxeJHAW6hPJXc+h6UlQkchToEspfPSmqhi4SOb1+pqgI/PVaLuYxNXSRiFFDl1DynxRN5jd0XRQViQwFuoSSbegxB49Zx2qLra2FHZiI5CjQJZRsoBMvAbPM4lxxU0MXiRAFuoSSC/TSzGUXMy2fKxI1CnQJJfukKCWlAMEnFpkCXSRCFOgSSvaiaLah6yPoRKJHgS6h5KZccg09poYuEjEKdAklG+g+IK+h6z50kUhRoEsoHRdFMw1dnykqEj0KdAklF+gtmfvOY2ak1dBFIkWBLqHkLorG44CmXESiKFSgm9k5ZrbezDaa2be7ef0rZtZgZiuDP5f3/1ClkLINPV2SF+iachGJlF4X5zKzOHAn8HGgDlhmZk+7+9ouhz7q7tccgjFKBHTc5ZIJ9MxH0LkCXSRCwjT0WcBGd3/b3duB+cDcQzssiZrcg0WachGJrDCBPhaozduuC/Z19Y9mtsrMHjez8d29kZldaWY1ZlbT0NDwHoYrhZK7bTF7H7qpoYtETX9dFH0GqHb3U4BFwAPdHeTu89x9prvPrKys7KcfLYeDp7OBroYuElVhAn0rkN+4xwX7ctx9t7tnl927B/hA/wxPosJTyczf+Y/+q6GLREqYQF8GTDWzSWY2ALgIeDr/ADMbnbd5PrCu/4YokZAIAj3voihAOp2CZLJgwxKRDr3e5eLuSTO7BngOiAP3ufsaM7sFqHH3p4H/aWbnA0lgD/CVQzhmKYQgtNN5DR0gZRA7eBAGDy7Y0EQkI9Rnirr7AmBBl3035n39HeA7/Ts0iRJPJoinIdk10GNQqkAXiQQ9KSrhJJOZD4guDaZcrKOhax5dJBoU6BJOMpn5gOgBHXe5QKah09JSwIGJSJYCXcJpbyeehvayjk8sgqChNzUVcGAikqVAl1AskSDu0F42AOjS0BsbCzgyEclSoEs4icxF0URZx3rooIYuEiUKdAknkQwaepcplxjcvuVRrl14bSFHJyIo0CWs4LbFXKBb5lcnZfBs43KefOPJQo5ORAh5H7oIySRxwOOZIM9v6A3J/ew8sBd3z93OKCKHnxq6hJNI5kIc8gI9buxMN9GWaqO5vblQoxMRFOgSkrW1EYt1/LpkL4omjimjgcx96DsP7CzI2EQkQ4EuoVh7OxaL57azDb2h8hjSlvm8UQW6SGEp0KVHG/dsZNKPJrGrZRfW1o5lPyiajkCvryjL7VOgixSWAl16tGzrMjbv20xt/RuQSkF+Qw8uftYPL83tU6CLFJYCXXpU11gHQMumN0lZx9K5kNfQyzt+hRToIoWl2xalR9lA37urFo93DvTsRdH6oZm/YxZToIsUmBq69KiuKRPoO9r3cHBwGZZ3l0uuoQ9KEUtDdWkVO1sU6CKFpECXHmUbel1pK61DBnV7H3p96UEqWmB0qkwNXaTAFOjSo2ygbxsC+weXdg704KLodpqpOhin6oDm0EUKTYEu3Ur+191sb97OlPbMR8vVlrZ029B3pZupSpRSVbtXgS5SYAp06db2dCNpT/P3mzPb+5PNnQLd8r6u4liqdh9kV8suUukUAC2JFhKpxOEcsshRT4Eu3apL7QXg71d3rM9i3TR0gMr4UCr3tJH2NHta9wBwxj1n8K3nv3WYRisioNsWpQfZQD/ZKxlU0kxrsjU3bw4Qy+sCVWXHUXVgE5CZRy+JlbB652rKSsoQkcNHDV0AaE20cuKdJ/LUG08BUHcwMx8+fuLJVB5bCdDtHDpA1eCRVB3IfL3zwE5W7VgFwOqdq0mmk4dj+CKCAl0CNdtqeGPXG/x6/a/Bnbq3V1KWgBHv/yCVmcUUO7Xy/LZeVT6620A/mDzIxj0bD9s5iBztFOgCwJK6JZm/t/wZHnyQuj2bGZc+FqueRGUsc6dL54uiHaoGjKBqwDCgc6ADvLb9tUM+dhHJUKALAEu3LgXgjT0b2PfVr1BXOZBxJ3wQzKiMDQHeZcolNoQR5aOIeSbQX9vxGmePP5uSWEku3BOpBFc/ezVv7HrjMJ6VyNFFgX6UumPpHTyz/pnc9pK6JYxpHwjAK9WlbK0sY1z5OICOhm75DT3vomhsCPHKkVS0GPXN21i9czWzxs5iWsU0Vu3MBPqLm1/krpq7+PHSHx/ycxM5WinQj0K7WnZx/e+u5/rfXY+7U9dYx9amrXx1GZjDXy79GFtjzYwbkg30nhv6QEoYYmUwahRVzc6fN/+J1mQrp4w8hVNGnpKbcnlqfeZi69Prn8bz1lXXRVOR/qNAPwq8Wv8qz254Nrf9yzW/JJlOsnHPRmq21bC0LjPd8om1bUxPDOOZ5BoSpBg7dCwAw2wQJcS6vQ+9KjYk88HQVVVUHYB1e98EYMbIGcwYOYPaxlr2tO7hqfVPMWTAELY2bWV5/XIAFr21iCH/PoRX6189LP8cRIqdAr3IpNIpNu/bnNtOpBJ87pef4zOPfYZ39r0DwMOvP8zk4ZMZGB/Iw68/zNIF8xhACaduhzMGHs/yxBYAxi1ZC2SWxp1eMpqx8WG5981Ov1TFM+2dCRNyd7rEiXFi5YmcsjyzFswDKx+grrGO7835HnGL526NvPmPN3MweZBbX7o1975v7HqDu5fd3anFi0g4CvQjWFuyjcfWPEZrojW37/JnLuf4Hx3PHzb9AYB7X72Xt/a+RSKV4OY/3szmfZt5ufZlLjvtMj51wqeYv3o+L7Vv5LTWcgZWjuLMISfm3mtcrCPArz52DucMPCm33dHQh2Z2DB1KFccAMK25jLIX/sSM0vEAfP/P3ydmMb4040t8aMKHeGr9U7y05SVern2ZycMn86u1v+LN3W/Smmhl7vy5XLXgKh5a9VDuZ/181c+5e9ndnc49u8SAiHQIFehmdo6ZrTezjWb27W5eH2hmjwavLzWz6v4eaDHbf3A/Wxu35rbdnV+8/gsWvrkwt2/1ztXMvnc2/7b430h7mkQqwYWPX8iFj1/IBY9eQFuyjUdef4T7V97PwJKBfPGJL1K7v5Zb/ngLZ40/i+vOvI4HXnuAG1+4EYB/OvmfuPjki9lxYAd/SbzNmesPwJw5nDlgcu5njosP73HMljflklVVNQmAUza1wAUXMGrtO1QMqmB783bOHn82FcdUMPd9c3l95+tc+9trOW7QcSy6ZBED4gO47c+38b0Xv8eG3RuYPHwy1/72Wuqb6pm/ej6XPHkJVy24Khfqr9a/SvWPqjn/kfNpbs8sTbC9eTv//Lt/ZtnWZbnxtCRaWFK3pFP4Z//ZiRSjXh/9N7M4cCfwcaAOWGZmT7v72rzD/gew192nmNlFwP8FLjwUA97auJWXtrzE9MrpnHDcCTS2NbJ652r2HdzH9MrpHD/8eGoba3MX42aMmsHYIWNZ27CWldtXMmLQCGaOmcnQgUOp2VbDqh2rmDJiCmeMO4NEKsHidxazcc9GPjDmA8weN5vaxloWvbWI3a27mVM9h1ljZ/HK1ld4dsOzlMRK+NQJn+KkypN4ZsMzPLPhGSaWT+TCky5kxKAR3LPiHhZuXMiHJ36YK06/gh0HdnDbn29jSd0SLj75Yq7+4NUs3LiQ/3jpP2hsa+TLp36ZK06/gptevInn334egC+8/wucM+Ucrl5wNal0iiV1S3h1+6uUxEp4av1TXPT+i5i/ej7nzz+fJXVLmD1uNj8+98ecfd/ZzPzZTHYe2Mn8z87nxIoT+dmKn/HQqoc4e/zZVA+rZlSyjPJ0KftjCc7YeBDmVDC9ZDSDbSAHPdEprLvKrYee2se8lsUArJ9wDLTBjBPnwEvrsJ/cyYyrBvP7Kpj7vrkAzJ02l+t/dz0r6ldw85ybmTR8Epeddhn3rLiHlKe4/LTLueGsGzj1v07lgkcvYOX2lfzdhL+jvKycaxZew7ambfxw6Q85pvQYnn3zWebcP4evz/o6Nyy6gV0tu/jh0h9y44dvZMqIKXzr+W9R21jLjJEz+M9P/CfbmrZx60u3snnfZq44/QqumXUNL295mXkr5gFw+WmXc+7Uc1nw5gKeWPcEY4eM5eJTLuaE407gNxt+w+J3FnPqqFO5YNoFlMZKee6t51jXsI7Z42fz0UkfpaGlgT9u/iO7W3fzoQkfYuaYmby5+02W1C0hHosze9xsJo+YzOqdq3m1/lUqj63kg2M+yLCyYazasYoNuzcwafgkTh11KmlP8/qO19nWtI1pFdOYVjGNfQf3saZhDQfaD3Bi5YlUD6umvqmeDbs3UBIrYVrFNCqOqeCd/e/w1p63GDFoBFOPm0pZSRmb9m5ia9NWxgwZw6Rhk0imk2zat4k9rXuYWD6RcUPH0dTexKa9m2hPtVM9rJqqY6toaGngnX3vMCA+gOph1QwZOIT6pnrqGusoLytnYvlESmIlbG3ayo7mHYwcPJKxQ8aSTCepbaylsa2RsUPGMnLwSJrbm6ndX0synWR8+XiGlw1nT+seahtrGRgfyPjy8RxTegw7mnewrWkbw8qGMW7oOGIWY1vTNhpaGhg1eBSjB4+mPdVObWMtTW1NjBs6jqpjq2hsa2TL/i2kPc2E8gkMKxtGQ0sDtftrGVQ6iAnlExhUMohtTdvY1rSNEYNGMKF8AgBb9m9hV8suxgwZw9ihYzmYPMimvZtobm9m4rCJjBo8ij2te3h779sAHD/8eEYMGsHWxq1s2reJwQMGM3n4ZAaVDmLT3k1s2b+FUYNHMWXEFNKeZsPuDWxv3k71sGomj5jMgPiA/g9HwHqbqzSz2cD33P2TwfZ3ANz93/OOeS445i9mVgJsByr9Xd585syZXlNT0+cB/3zVz7nkyUsyPxfD6fwjutvXH+IWJ+UdTa+spIy0p2lPtef2jR86np0HdtKWast9z1njz2LZtmUcTB4EYMyQMXx44od5ct2TueM+fcKnmTJ8CnfV3EV7qp3BAwbz/Y99n10tu/jXxf9KIp1g1thZPPH5J3hszWPcsOgG0p7mto/fxg1n3cCdr9zJNQuvoXxgOSu/upLqYdX8aMmPuO656zhnyjksvDjT9G964SZuWXwLd513F1979C24/Xau+G/OPafDW1Pu4PmdfwEzbm9+nl3pZm4dekGP/zwOpNu4vulx/rHsND4xcDoAryXquKvljywY/nXO/cL/hm98g+v3zucHMxNsaL6UqbfdB8DJd5/M23vfZst1WzjumON4e+/bTL1jKqMHj2bNVWsoLyvntpdv45vPf5NpFdN4+bKXGRgfyEce+AjLti1jxsgZLLh4ASvqV3Dh4xfSkmjh9NGnc+d5d3LHK3fwi9d/AcBpo07jyzO+zA+W/IB39meuH5wy8hROrjqZR9c8mrvDZnrldAxjTcOa3PkdP/x4djTv4EDiQG5fxTEV7GrZ1emfQ2mslET60Df+sL/rMYuR9vS7Hhf2+8Lu6/p+Yb+v6/+metrX9Xv7873+lvGH3ddV3OJ89+++yy0fueVdj+uJmS1395ndvhYi0D8LnOPulwfblwBnuPs1ecesDo6pC7bfCo7Z1eW9rgSuDDbfB6x/T2cUHRXArl6PKj5H43kfjecMOu8omujuld29cFhXW3T3ecC8w/kzDyUzq+np/ymL2dF43kfjOYPOu9Dj6KswF0W3AuPztscF+7o9JphyKQd298cARUQknDCBvgyYamaTzGwAcBHwdJdjnga+HHz9WeAP7zZ/LiIi/a/XKRd3T5rZNcBzQBy4z93XmNktQI27Pw3cCzxkZhuBPWRC/2hQNNNHfXQ0nvfReM6g8z6i9HpRVEREjgx6UlREpEgo0EVEioQC/T0ws8+Z2RozS5vZzC6vfSdYAmG9mX2yUGM8FHpbAqJYmNl9ZrYzeL4iu2+EmS0yszeDv3teF+EIZWbjzewFM1sb/H5fG+wv2nM3szIze8XMXgvO+eZg/6RgGZONwbImh+bRzn6mQH9vVgOfARbn7zSz6WQuCJ8EnAPcFSydcMTLWwLiXGA68IXgfIvR/WT+/eX7NvB7d58K/D7YLjZJ4BvuPh04E7g6+HdczOfeBvyDu88ATgXOMbMzySxf8gN3nwLsJbO8SeQp0N8Dd1/n7t095ToXmO/ube6+CdgIzDq8oztkZgEb3f1td28H5pM536Lj7ovJ3K2Vby7wQPD1A0DP6yIcody93t1XBF83AeuAsRTxuXtGc7BZGvxx4B+Ax4P9R8w5K9D711igNm+7LthXDIr53MIY6e71wdfbgZGFHMyhFqyYehqwlCI/dzOLm9lKYCewCHgL2Ofu2Y/TOmJ+1w/ro/9HEjN7HhjVzUv/4u5PHe7xSHS4u5tZ0d7va2aDgV8B17l7o+V9lmwxnru7p4BTzWwY8CQwrcBDes8U6D1w94+9h28Ls0zCkaqYzy2MHWY22t3rzWw0mTZXdMyslEyYP+zuTwS7j4pzd/d9ZvYCMBsYZmYlQUs/Yn7XNeXSv54GLgo+8GMSMBV4pcBj6i9hloAoZvnLW3wZKLr/SrNMFb8XWOfut+e9VLTnbmaVQTPHzAaR+dyHdcALZJYxgSPonPWk6HtgZv8duAOoBPYBK/PWi/8X4DIydwxc5+4Le3yjI4yZnQf8kI4lIP5PgYd0SJjZI8AcMkuo7gBuAn4NPAZMAN4BPu/uXS+cHtHM7EPAn4DXgeyi3t8lM49elOduZqeQuegZJ1NwH3P3W8zseDIX/kcArwJfdPe2wo00HAW6iEiR0JSLiEiRUKCLiBQJBbqISJFQoIuIFAkFuohIkVCgy1ElWE3wk132XWdmC83sL8GKe6vM7MK81z9qZivMbKWZvWRmUw7/yEV6p9sW5ahiZlcCs9390rx9S4BvAvXu/qaZjQGWAycGTw9uAOa6+zozuwqY5e5fKcT4Rd6NGrocbR4HPpVd3zpYhGoM8Cd3fxPA3beReby9MvgeB4YGX5cD2w7jeEVC01ouclRx9z1m9gqZdd2fIrOEwWOe95+qZjYLGEBm1T2Ay4EFZtYKNJJZK1wkctTQ5Wj0CJkgJ/j7kewLweJTDwGXunv28ff/BZzn7uOA/wfkr3MiEhmaQ5ejTrA87NtkPpVovrufEOwfCrwI3Orujwf7KoEl7j452J4A/Db4VB+RSFFDl6NO8Ak1LwD3EbTzYE79SeDBbJgH9gLlZnZCsArI1TMAAABjSURBVJ1djU8kcjSHLkerR8gEeHbq5fPAh4HjzOwrwb6vuPtKM7sC+JWZpckE/GWHe7AiYWjKRUSkSGjKRUSkSCjQRUSKhAJdRKRIKNBFRIqEAl1EpEgo0EVEioQCXUSkSPx/FhW9+s/W+68AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FS9H8cZi24b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x = creditcard.drop(['Class','Time'],axis=1)\n",
        "y = creditcard.Class\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJ2B4GVRi6p6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## logistic regression after removing some featuers\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model_lr = LogisticRegression()\n",
        "model_lr.fit(x_train, y_train)\n",
        "ACC_train_lr = model_lr.score(x_train, y_train)\n",
        "ACC_test_lr = model_lr.score(x_test, y_test)\n",
        "\n",
        "x_train2=x_train.drop(['V13','V20','V23','V28'],axis=1)\n",
        "x_test2=x_test.drop(['V13','V20','V23','V28'],axis=1)\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model_lr2 = LogisticRegression()\n",
        "model_lr2.fit(x_train2, y_train)\n",
        "ACC_train_lr2 = model_lr2.score(x_train2, y_train)\n",
        "ACC_test_lr2 = model_lr2.score(x_test2, y_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX4fqjh5b21k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "9c88be29-cd5b-429f-fb1a-a22457c870a7"
      },
      "source": [
        "## accuracy\n",
        "lr_pred = model_lr.predict(x_test)\n",
        "lr_pred2 = model_lr2.predict(x_test2)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "lr_accuracy_score=  accuracy_score(y_test, lr_pred)\n",
        "lr_accuracy_score2=  accuracy_score(y_test, lr_pred2)\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "lr_f1_score= f1_score(y_test, lr_pred)\n",
        "lr_f1_score2= f1_score(y_test, lr_pred2)\n",
        "\n",
        "from sklearn.metrics import recall_score\n",
        "lr_recall_score= recall_score(y_test, lr_pred)\n",
        "lr_recall_score2= recall_score(y_test, lr_pred2)\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "t2 = PrettyTable(['Accuracy', 'Logistic (%)' , 'Logistic v2 (%)' ])\n",
        "t2.add_row(['accuracy_score', lr_accuracy_score*100, lr_accuracy_score2*100])\n",
        "t2.add_row(['f1_score',       lr_f1_score*100      , lr_f1_score2*100      ])\n",
        "t2.add_row(['recall_score',   lr_recall_score*100  , lr_recall_score2*100  ])\n",
        "print(t2)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------+-------------------+-------------------+\n",
            "|    Accuracy    |    Logistic (%)   |  Logistic v2 (%)  |\n",
            "+----------------+-------------------+-------------------+\n",
            "| accuracy_score | 99.90871107053826 | 99.91222218320986 |\n",
            "|    f1_score    | 64.86486486486487 | 67.94871794871794 |\n",
            "|  recall_score  | 51.06382978723404 | 56.38297872340425 |\n",
            "+----------------+-------------------+-------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QW-SX_n5qvQ-",
        "colab_type": "text"
      },
      "source": [
        "Observations:\n",
        "\n",
        "Execluding irrelevant featuers ('V13','V20','V23','V28') shows minor enhancemnt in accurecy "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BreCYwncEQcj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## logistic regression after removing some featuers\n",
        "from sklearn.ensemble import RandomForestClassifier \n",
        "model_rf = RandomForestClassifier()\n",
        "model_rf.fit(x_train,y_train)\n",
        "ACC_train_lr = model_rf.score(x_train, y_train)\n",
        "ACC_test_lr = model_rf.score(x_test, y_test)\n",
        "\n",
        "x_train2=x_train.drop(['V13','V20','V23','V28'],axis=1)\n",
        "x_test2=x_test.drop(['V13','V20','V23','V28'],axis=1)\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier \n",
        "model_lr2 = RandomForestClassifier()\n",
        "model_lr2.fit(x_train2,y_train)\n",
        "ACC_train_lr2 = model_lr2.score(x_train2, y_train)\n",
        "ACC_test_lr2 = model_lr2.score(x_test2, y_test)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEAJAsENESki",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "5aa92fe5-0241-4002-a2ea-c779c45591d1"
      },
      "source": [
        "## accuracy\n",
        "lr_pred = model_lr.predict(x_test)\n",
        "lr_pred2 = model_lr2.predict(x_test2)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "lr_accuracy_score=  accuracy_score(y_test, lr_pred)\n",
        "lr_accuracy_score2=  accuracy_score(y_test, lr_pred2)\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "lr_f1_score= f1_score(y_test, lr_pred)\n",
        "lr_f1_score2= f1_score(y_test, lr_pred2)\n",
        "\n",
        "from sklearn.metrics import recall_score\n",
        "lr_recall_score= recall_score(y_test, lr_pred)\n",
        "lr_recall_score2= recall_score(y_test, lr_pred2)\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "t2 = PrettyTable(['Accuracy', 'Logistic (%)' , 'Logistic v2 (%)' ])\n",
        "t2.add_row(['accuracy_score', lr_accuracy_score*100, lr_accuracy_score2*100])\n",
        "t2.add_row(['f1_score',       lr_f1_score*100      , lr_f1_score2*100      ])\n",
        "t2.add_row(['recall_score',   lr_recall_score*100  , lr_recall_score2*100  ])\n",
        "print(t2)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------+-------------------+-------------------+\n",
            "|    Accuracy    |    Logistic (%)   |  Logistic v2 (%)  |\n",
            "+----------------+-------------------+-------------------+\n",
            "| accuracy_score | 99.91397773954567 | 99.96664442961975 |\n",
            "|    f1_score    | 71.00591715976331 | 89.72972972972973 |\n",
            "|  recall_score  |        60.0       |        83.0       |\n",
            "+----------------+-------------------+-------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJVWJJIhG-Tg",
        "colab_type": "text"
      },
      "source": [
        "Observations:\n",
        "\n",
        "Execluding irrelevant featuers ('V13','V20','V23','V28') shows **good** enhancemnt in accurecy when using random forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNzOX1gDFwRo",
        "colab_type": "text"
      },
      "source": [
        "# Exploratory Data Analysis EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sDmHOisp_i7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "creditcard.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvx6lBojqH6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "creditcard.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wS5hmDvyObf2",
        "colab_type": "text"
      },
      "source": [
        "We used the plot above to check the distribution of observations for each featur and one by one , for example V4: shows clear distinction between fraud & genuine transactions, while V28 didn't."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiLPTVh3txYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_plot(plot_rows,plot_col,i,col):\n",
        "    plt.subplot(plot_rows,plot_col,i)\n",
        "    sns.boxplot(x='Class',y=col,data=creditcard)\n",
        "\n",
        "plt.figure(figsize=(24,12))\n",
        "axs = [ my_plot(6,5,i,'V'+str(i)) for i in range(1,29)]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACtKZJ7eFwRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.boxplot(x = \"Class\", y = \"Time\", data = creditcard)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVUhmVkT09Zb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set_style(\"whitegrid\")\n",
        "sns.FacetGrid(creditcard, hue=\"Class\", size = 6).map(plt.scatter, \"Time\", \"Amount\").add_legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrurYDXdFwRr",
        "colab_type": "text"
      },
      "source": [
        "Observations:\n",
        "\n",
        "By looking at the above plot we can say that both fraud & genuine transactions occur throughout time and there is no distinction between them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eO6e7PhB5OuR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.scatterplot(x = \"Class\", y = \"Amount\", data = creditcard)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nAc8QOeFwRu",
        "colab_type": "text"
      },
      "source": [
        "Observations:\n",
        "\n",
        "From above box plot we can easily infer that there are no fraud transactions occur above the transaction amount of 3000. All of the fraud transactions have transaction amount less than 3000. However, there are many transactions which have a transaction amount greater than 3000 and all of them are genuine."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_KmCnlJF2No",
        "colab_type": "text"
      },
      "source": [
        "**ECDF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqaQccHsF9K6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating our ecdf function\n",
        "def ecdf(data,i):\n",
        "    xaxis = np.sort(data)\n",
        "    yaxis = np.arange(1,len(data)+1)/len(data)\n",
        "    plt.plot(xaxis,yaxis,linestyle='none',marker='.')\n",
        "    plt.title('ECDF of average V'+str(i))\n",
        "\n",
        "creditcardFraud=creditcard[creditcard['Class']==1]\n",
        "creditcardNotFraud=creditcard[creditcard['Class']==0]\n",
        "\n",
        "for i in range(1,29):\n",
        "    ecdf(creditcardFraud['V'+str(i)],i)\n",
        "    ecdf(creditcardNotFraud['V'+str(i)],i)\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeLFM-jTloZt",
        "colab_type": "text"
      },
      "source": [
        "#Try Different classifiers (unbalanced)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l42qxWRa4L5Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a2e99427-2db5-4e12-df0d-dd1c39701453"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x = creditcard.drop('Class',axis=1)\n",
        "y = creditcard.Class\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2)\n",
        "print('size of test dataset = {}, size of traing data = {}, percentage = {}%'.format(len(x_test),len(x_train),len(x_test)*100/(len(x_test) + len(x_train))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "size of test dataset = 56962, size of traing data = 227845, percentage = 20.000210668979342%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LcJURKW4uTK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "ada2267a-ad37-4d4b-e29d-0d3cc8990a22"
      },
      "source": [
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284802</th>\n",
              "      <td>172786.0</td>\n",
              "      <td>-11.881118</td>\n",
              "      <td>10.071785</td>\n",
              "      <td>-9.834783</td>\n",
              "      <td>-2.066656</td>\n",
              "      <td>-5.364473</td>\n",
              "      <td>-2.606837</td>\n",
              "      <td>-4.918215</td>\n",
              "      <td>7.305334</td>\n",
              "      <td>1.914428</td>\n",
              "      <td>4.356170</td>\n",
              "      <td>-1.593105</td>\n",
              "      <td>2.711941</td>\n",
              "      <td>-0.689256</td>\n",
              "      <td>4.626942</td>\n",
              "      <td>-0.924459</td>\n",
              "      <td>1.107641</td>\n",
              "      <td>1.991691</td>\n",
              "      <td>0.510632</td>\n",
              "      <td>-0.682920</td>\n",
              "      <td>1.475829</td>\n",
              "      <td>0.213454</td>\n",
              "      <td>0.111864</td>\n",
              "      <td>1.014480</td>\n",
              "      <td>-0.509348</td>\n",
              "      <td>1.436807</td>\n",
              "      <td>0.250034</td>\n",
              "      <td>0.943651</td>\n",
              "      <td>0.823731</td>\n",
              "      <td>0.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284803</th>\n",
              "      <td>172787.0</td>\n",
              "      <td>-0.732789</td>\n",
              "      <td>-0.055080</td>\n",
              "      <td>2.035030</td>\n",
              "      <td>-0.738589</td>\n",
              "      <td>0.868229</td>\n",
              "      <td>1.058415</td>\n",
              "      <td>0.024330</td>\n",
              "      <td>0.294869</td>\n",
              "      <td>0.584800</td>\n",
              "      <td>-0.975926</td>\n",
              "      <td>-0.150189</td>\n",
              "      <td>0.915802</td>\n",
              "      <td>1.214756</td>\n",
              "      <td>-0.675143</td>\n",
              "      <td>1.164931</td>\n",
              "      <td>-0.711757</td>\n",
              "      <td>-0.025693</td>\n",
              "      <td>-1.221179</td>\n",
              "      <td>-1.545556</td>\n",
              "      <td>0.059616</td>\n",
              "      <td>0.214205</td>\n",
              "      <td>0.924384</td>\n",
              "      <td>0.012463</td>\n",
              "      <td>-1.016226</td>\n",
              "      <td>-0.606624</td>\n",
              "      <td>-0.395255</td>\n",
              "      <td>0.068472</td>\n",
              "      <td>-0.053527</td>\n",
              "      <td>24.79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284804</th>\n",
              "      <td>172788.0</td>\n",
              "      <td>1.919565</td>\n",
              "      <td>-0.301254</td>\n",
              "      <td>-3.249640</td>\n",
              "      <td>-0.557828</td>\n",
              "      <td>2.630515</td>\n",
              "      <td>3.031260</td>\n",
              "      <td>-0.296827</td>\n",
              "      <td>0.708417</td>\n",
              "      <td>0.432454</td>\n",
              "      <td>-0.484782</td>\n",
              "      <td>0.411614</td>\n",
              "      <td>0.063119</td>\n",
              "      <td>-0.183699</td>\n",
              "      <td>-0.510602</td>\n",
              "      <td>1.329284</td>\n",
              "      <td>0.140716</td>\n",
              "      <td>0.313502</td>\n",
              "      <td>0.395652</td>\n",
              "      <td>-0.577252</td>\n",
              "      <td>0.001396</td>\n",
              "      <td>0.232045</td>\n",
              "      <td>0.578229</td>\n",
              "      <td>-0.037501</td>\n",
              "      <td>0.640134</td>\n",
              "      <td>0.265745</td>\n",
              "      <td>-0.087371</td>\n",
              "      <td>0.004455</td>\n",
              "      <td>-0.026561</td>\n",
              "      <td>67.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284805</th>\n",
              "      <td>172788.0</td>\n",
              "      <td>-0.240440</td>\n",
              "      <td>0.530483</td>\n",
              "      <td>0.702510</td>\n",
              "      <td>0.689799</td>\n",
              "      <td>-0.377961</td>\n",
              "      <td>0.623708</td>\n",
              "      <td>-0.686180</td>\n",
              "      <td>0.679145</td>\n",
              "      <td>0.392087</td>\n",
              "      <td>-0.399126</td>\n",
              "      <td>-1.933849</td>\n",
              "      <td>-0.962886</td>\n",
              "      <td>-1.042082</td>\n",
              "      <td>0.449624</td>\n",
              "      <td>1.962563</td>\n",
              "      <td>-0.608577</td>\n",
              "      <td>0.509928</td>\n",
              "      <td>1.113981</td>\n",
              "      <td>2.897849</td>\n",
              "      <td>0.127434</td>\n",
              "      <td>0.265245</td>\n",
              "      <td>0.800049</td>\n",
              "      <td>-0.163298</td>\n",
              "      <td>0.123205</td>\n",
              "      <td>-0.569159</td>\n",
              "      <td>0.546668</td>\n",
              "      <td>0.108821</td>\n",
              "      <td>0.104533</td>\n",
              "      <td>10.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284806</th>\n",
              "      <td>172792.0</td>\n",
              "      <td>-0.533413</td>\n",
              "      <td>-0.189733</td>\n",
              "      <td>0.703337</td>\n",
              "      <td>-0.506271</td>\n",
              "      <td>-0.012546</td>\n",
              "      <td>-0.649617</td>\n",
              "      <td>1.577006</td>\n",
              "      <td>-0.414650</td>\n",
              "      <td>0.486180</td>\n",
              "      <td>-0.915427</td>\n",
              "      <td>-1.040458</td>\n",
              "      <td>-0.031513</td>\n",
              "      <td>-0.188093</td>\n",
              "      <td>-0.084316</td>\n",
              "      <td>0.041333</td>\n",
              "      <td>-0.302620</td>\n",
              "      <td>-0.660377</td>\n",
              "      <td>0.167430</td>\n",
              "      <td>-0.256117</td>\n",
              "      <td>0.382948</td>\n",
              "      <td>0.261057</td>\n",
              "      <td>0.643078</td>\n",
              "      <td>0.376777</td>\n",
              "      <td>0.008797</td>\n",
              "      <td>-0.473649</td>\n",
              "      <td>-0.818267</td>\n",
              "      <td>-0.002415</td>\n",
              "      <td>0.013649</td>\n",
              "      <td>217.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>284807 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Time         V1         V2  ...       V27       V28  Amount\n",
              "0            0.0  -1.359807  -0.072781  ...  0.133558 -0.021053  149.62\n",
              "1            0.0   1.191857   0.266151  ... -0.008983  0.014724    2.69\n",
              "2            1.0  -1.358354  -1.340163  ... -0.055353 -0.059752  378.66\n",
              "3            1.0  -0.966272  -0.185226  ...  0.062723  0.061458  123.50\n",
              "4            2.0  -1.158233   0.877737  ...  0.219422  0.215153   69.99\n",
              "...          ...        ...        ...  ...       ...       ...     ...\n",
              "284802  172786.0 -11.881118  10.071785  ...  0.943651  0.823731    0.77\n",
              "284803  172787.0  -0.732789  -0.055080  ...  0.068472 -0.053527   24.79\n",
              "284804  172788.0   1.919565  -0.301254  ...  0.004455 -0.026561   67.88\n",
              "284805  172788.0  -0.240440   0.530483  ...  0.108821  0.104533   10.00\n",
              "284806  172792.0  -0.533413  -0.189733  ... -0.002415  0.013649  217.00\n",
              "\n",
              "[284807 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiaplVab4vu_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "il-Q3p2i5urf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "e20223d4-03f2-4cd5-c2aa-655d4fa73696"
      },
      "source": [
        "## logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model_lr = LogisticRegression()\n",
        "model_lr.fit(x_train, y_train)\n",
        "ACC_train_lr = model_lr.score(x_train, y_train)\n",
        "ACC_test_lr = model_lr.score(x_test, y_test)\n",
        "print(ACC_train_lr*100)\n",
        "print(ACC_test_lr*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99.885448440826\n",
            "99.89115550718023\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFj46Gds5RlJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3dd090bc-6ffe-4a11-fb19-4c76534340de"
      },
      "source": [
        "##  Decision tree\n",
        "from sklearn import tree\n",
        "model_dt = tree.DecisionTreeClassifier()\n",
        "model_dt.fit(x_train,y_train)\n",
        "ACC_train_dt = model_dt.score(x_train,y_train)\n",
        "ACC_test_dt = model_dt.score(x_test,y_test)\n",
        "print(ACC_train_dt*100)\n",
        "print(ACC_test_dt*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100.0\n",
            "99.9367999719111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2S6Ner1c65NK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4a519508-8294-4ba7-f5b0-e04ea35fd53a"
      },
      "source": [
        "## Support Vector Machine\n",
        "from sklearn.svm import SVC \n",
        "model_svm = SVC()\n",
        "model_svm.fit(x_train, y_train)\n",
        "ACC_train_svm = model_svm.score(x_train, y_train)\n",
        "ACC_test_svm = model_svm.score(x_test, y_test)\n",
        "print(ACC_train_svm*100)\n",
        "print(ACC_test_svm*100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99.83058658298405\n",
            "99.8139110284049\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4jkgEHG7li2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0999341b-ca39-4cec-9329-49ca4b24d0d3"
      },
      "source": [
        "## Random Forest \n",
        "from sklearn.ensemble import RandomForestClassifier \n",
        "model_rf = RandomForestClassifier()\n",
        "model_rf.fit(x_train,y_train)\n",
        "ACC_train_rf = model_rf.score(x_train, y_train)\n",
        "ACC_test_rf = model_rf.score(x_test, y_test)\n",
        "print(ACC_train_rf*100)\n",
        "print(ACC_test_rf*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100.0\n",
            "99.95786664794073\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcvqTBP8D8y3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "704d7679-4768-4ee8-f2f8-2b565296cae5"
      },
      "source": [
        "## Naive Bayse\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "model_nb = GaussianNB()\n",
        "model_nb.fit(x_train,y_train)\n",
        "ACC_train_nb = model_nb.score(x_train,y_train)\n",
        "ACC_test_nb = model_nb.score(x_test,y_test)\n",
        "print(ACC_train_nb*100)\n",
        "print(ACC_test_nb*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99.26133994601594\n",
            "99.29777746567888\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmKCgZ4z56pH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "4353a9ef-c330-42d2-ee02-632ffb9c3312"
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "t = PrettyTable(['Accuracy', 'Logistic (%)' , 'DT (%)' , 'SVM (%)' , 'RF (%)' , 'NB (%)'])\n",
        "t.add_row(['Training', ACC_train_lr*100, ACC_train_dt*100, ACC_train_svm*100, ACC_train_rf*100 , ACC_train_nb*100])\n",
        "t.add_row(['Testing', ACC_test_lr*100, ACC_test_dt*100, ACC_test_svm*100, ACC_test_rf*100 , ACC_test_nb*100])\n",
        "print(t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-------------------+------------------+-------------------+-------------------+-------------------+\n",
            "| Accuracy |    Logistic (%)   |      DT (%)      |      SVM (%)      |       RF (%)      |       NB (%)      |\n",
            "+----------+-------------------+------------------+-------------------+-------------------+-------------------+\n",
            "| Training |  99.885448440826  |      100.0       | 99.83058658298405 |       100.0       | 99.26133994601594 |\n",
            "| Testing  | 99.89115550718023 | 99.9367999719111 |  99.8139110284049 | 99.95786664794073 | 99.29777746567888 |\n",
            "+----------+-------------------+------------------+-------------------+-------------------+-------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzEUWiVaIHJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use differant performance metric on DT\n",
        "lr_pred = model_lr.predict(x_test)\n",
        "dt_pred = model_dt.predict(x_test)\n",
        "svm_pred = model_svm.predict(x_test)\n",
        "rf_pred = model_rf.predict(x_test)\n",
        "nb_pred = model_nb.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERTfR-U2Q4Jh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "lr_accuracy_score=  accuracy_score(y_test, lr_pred)\n",
        "dt_accuracy_score=  accuracy_score(y_test, dt_pred)\n",
        "svm_accuracy_score=  accuracy_score(y_test, svm_pred)\n",
        "rf_accuracy_score=  accuracy_score(y_test, rf_pred)\n",
        "nb_accuracy_score=  accuracy_score(y_test, nb_pred)\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "# f1 score : F1 score reaches its best value at 1 and worst score at 0\n",
        "lr_f1_score= f1_score(y_test, lr_pred)\n",
        "dt_f1_score= f1_score(y_test, dt_pred)\n",
        "svm_f1_score= f1_score(y_test, svm_pred)\n",
        "rf_f1_score= f1_score(y_test, rf_pred)\n",
        "nb_f1_score= f1_score(y_test, nb_pred)\n",
        "\n",
        "from sklearn.metrics import recall_score\n",
        "# recall score : The best value is 1 and the worst value is 0\n",
        "lr_recall_score= recall_score(y_test, lr_pred)\n",
        "dt_recall_score= recall_score(y_test, dt_pred)\n",
        "svm_recall_score= recall_score(y_test, svm_pred)\n",
        "rf_recall_score= recall_score(y_test, rf_pred)\n",
        "nb_recall_score= recall_score(y_test, nb_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmWuYRrcJiT7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "18c4c100-a23f-4372-ea02-2cb186ea4347"
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "t2 = PrettyTable(['Accuracy', 'Logistic (%)' , 'DT (%)' , 'SVM (%)' , 'RF (%)' , 'NB (%)'])\n",
        "t2.add_row(['accuracy_score', lr_accuracy_score*100, dt_accuracy_score*100, svm_accuracy_score*100, rf_accuracy_score*100 , nb_accuracy_score*100])\n",
        "t2.add_row(['f1_score',       lr_f1_score*100      , dt_f1_score*100      , svm_f1_score*100       , rf_f1_score*100       , nb_f1_score*100]      )\n",
        "t2.add_row(['recall_score',   lr_recall_score*100  , dt_recall_score*100  , svm_recall_score*100  , rf_recall_score*100   , nb_recall_score*100]  )\n",
        "print(t2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------+-------------------+-------------------+------------------+-------------------+-------------------+\n",
            "|    Accuracy    |    Logistic (%)   |       DT (%)      |     SVM (%)      |       RF (%)      |       NB (%)      |\n",
            "+----------------+-------------------+-------------------+------------------+-------------------+-------------------+\n",
            "| accuracy_score | 99.89115550718023 |  99.9367999719111 | 99.8139110284049 | 99.95786664794073 | 99.29777746567888 |\n",
            "|    f1_score    |  69.6078431372549 | 83.33333333333334 |       0.0        | 87.87878787878786 | 28.31541218637993 |\n",
            "|  recall_score  | 66.98113207547169 | 84.90566037735849 |       0.0        |  82.0754716981132 | 74.52830188679245 |\n",
            "+----------------+-------------------+-------------------+------------------+-------------------+-------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol-SUQB0GY4J",
        "colab_type": "text"
      },
      "source": [
        "# Cross Validation KFOLD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IebVsWSsMHtd",
        "colab_type": "text"
      },
      "source": [
        "**Cross Validation** is a very useful technique for assessing the performance of machine learning models. It helps in knowing how the machine learning model would generalize to an independent data set. and to estimate how accurate your model will predict in practice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZp7G_H0GeWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "##LR\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "ACC_test_lr = cross_val_score(LogisticRegression(),x,y)\n",
        "\n",
        "##DT\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "ACC_test_dt = cross_val_score(DecisionTreeClassifier(),x,y)\n",
        "\n",
        "##SVM\n",
        "from sklearn.svm import SVC\n",
        "ACC_test_svm = cross_val_score(SVC(),x,y)\n",
        "\n",
        "##RF\n",
        "## from sklearn.ensemble import RandomForestClassifier\n",
        "## ACC_test_rf = cross_val_score(RandomForestClassifier(),x,y)\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "ACC_test_rf4 = cross_val_score(RandomForestClassifier(),x,y,cv=StratifiedKFold(n_splits=5, shuffle=True))\n",
        "print(ACC_test_rf4)\n",
        "\n",
        "##NB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "ACC_test_nb = cross_val_score(GaussianNB(),x,y)\n",
        "\n",
        "\n",
        "ACC_test_lr_mean = np.mean(ACC_test_lr);\n",
        "ACC_test_dt_mean = np.mean(ACC_test_dt);\n",
        "ACC_test_svm_mean = np.mean(ACC_test_svm);\n",
        "ACC_test_rf_mean = np.mean(ACC_test_rf);\n",
        "ACC_test_nb_mean = np.mean(ACC_test_nb);\n",
        "\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "t = PrettyTable(['KVC Accuracy', 'Logistic (%)' , 'DT (%)' , 'SVM (%)' , 'RF (%)', 'NB (%)'])\n",
        "t.add_row(['Testing', ACC_test_lr_mean*100, ACC_test_dt_mean*100, ACC_test_svm_mean*100, ACC_test_rf_mean*100, ACC_test_nb_mean*100])\n",
        "print(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "herqaTv35V-l",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "SAAS API (prove of concept )\n",
        "\n",
        "Moh.....\n",
        "\n",
        "SMOT with RF\n",
        "\n",
        "transform ( save the model for prediction ) , then do fit\n",
        "\n",
        "assume featuers to PCA \n",
        "\n",
        "asma.....\n",
        "\n",
        "tuning of parameters \n",
        "\n",
        "ROC AUC curve"
      ]
    }
  ]
}